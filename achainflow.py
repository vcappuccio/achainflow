#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
achainflow.py

This script provides a Streamlit application that consults a chain of advisors using different AI models to solve coding problems and technical questions.
 
"""

import os
from dotenv import load_dotenv
import asyncio

import streamlit as st

from groq import Groq
from ollama import (
    AsyncClient,
)

load_dotenv()


groq_api_key = os.getenv("GROQ_API_KEY")
client = Groq(api_key=groq_api_key)


async def consult_api(model, system_message, user_message):
    """
    Asynchronously consult an advisor using the API and return the response message content.

    Args:
        model (str): The model to consult.
        system_message (str): The system message to be included in the consultation.
        user_message (str or list): The user message(s) to be included in the consultation.

    Returns:
        str: The advisor's response message content.
    """
    messages = [{"role": "system", "content": system_message}]

    if isinstance(user_message, list):
        messages.extend(
            {"role": "user", "content": msg} if isinstance(msg, str) else msg
            for msg in user_message
        )
    else:
        messages.append({"role": "user", "content": user_message})

    try:
        if model != "grok":
            response = await AsyncClient().chat(model=model, messages=messages)
            return response["message"]["content"].strip()
        else:
            response = client.chat.completions.create(
                messages=messages,
                model="llama3-70b-8192",
                temperature=0.1,
                max_tokens=4024,
            )
            return response.choices[0].message.content.strip()
    except Exception as e:
        return f"Error: {str(e)}"


async def get_over_a_chain_of_advisors_async(user_message):
    """
    Consult a chain of advisors using different models and return the final answer.

    Args:
        user_message (str): The user message to be consulted by the chain of advisors.

    Returns:
        str: The final answer generated by the chain of advisors.
    """
    system_message = """
You are Arquitech, an advanced AI assistant and code problem solver. Your only purpose is to help find 
the best solutions for any coding challenges and technical questions.
Let's get started! What challenge can I help you with today?    """
    models = {
        "phi3": "Microsoft PHI3",
        "mistral": "Mistral 7B",
        "gemma:latest": "Gemma 7B",
        "dolphin-mixtral:latest": "Dolphin Mixtral",
        "dolphin2.2-mistral:latest": "Dolphin2.2 Mistral",
        "openhermes:latest": "Openhermes",
        "codellama:latest": "CodeLlama",
    }

    advisors_answers = {}

    for model, name in models.items():
        st.markdown("---")
        st.markdown(f"### Processing {name}'s advice:")
        st.markdown("---")
        advice = await consult_api(model, system_message, user_message)
        if not advice:  # Check if advice is empty or None
            st.markdown(f"Model {name} doesn't have an answer for this.")
            continue  # Skip to the next model if no advice is given
            
        advisors_answers[name] = f"Provided the following advice:\n\n'''{advice}'''\n\n"

        st.markdown(advisors_answers[name])

        
    formatted_advisors_answers = ""
    for i, (advisor, answer) in enumerate(advisors_answers.items()):
        formatted_advisors_answers += f"|{i+1}| Start of Advisor: {advisor}: \n"
        formatted_advisors_answers += f"his answer:\n"
        formatted_advisors_answers += f"'''{answer}'''\n"
        formatted_advisors_answers += f"End of Advisor: {advisor} |"

    advisor_evaluation = f"""
    \n\n
    I need the most comprehensive and insightful answers, from the advisors who offer their unique perspectives and knowledge. 
    These advisors are specialized AI models, each with their own areas of expertise.
    
    You will carefully consider each advisor's input, analyzing their suggestions and weighing their relevance to the specific problem.
    
    You will synthesize their ideas with your own understanding and problem-solving capabilities. 
    
    You will aim to provide with a well-reasoned, step-by-step plan to tackle your challenge, drawing upon the collective wisdom of my advisors and my own expertise.
    
    Here are the advisors names and answers: \n
    {formatted_advisors_answers}

    for this problem:\n
    {user_message}
    \n
    
    Use the insights from the advisors to create a step-by-step plan to solve the given problem,
    then solve the problem your way taking all the advisors insights into account. Also, include footnotes to the best advisor contributions."""

    final_answer = await consult_api("llama3-gradient:latest", system_message, advisor_evaluation)

    st.markdown("---")
    return final_answer


async def main():
    """
    Main function to run the Streamlit application.
    """
    st.title("Multitude of Advisors")

    problem = st.text_area("Paste your problem: ")

    if st.button("Solve my problems"):
        with st.spinner("Broadcasting this problem to advisors..."):
            final_answer = await get_over_a_chain_of_advisors_async(problem)

        st.header("Distributed Answer")
        st.markdown(final_answer)


if __name__ == "__main__":
    asyncio.run(main())
